{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedbc150-8c5a-4efb-85ab-fa10c19b8e22",
   "metadata": {},
   "source": [
    "# Assignment #3: Dimensionality Reduction Methods\r\n",
    "\r\n",
    "**Using the \"modified_dataset.csv\" produced in Assignment #1**\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Overview\r\n",
    "\r\n",
    "This assignment consists of three parts:\r\n",
    "\r\n",
    "1. **PCA Method with Mean-Filling**  \r\n",
    "2. **PCA Method with Maximum Likelihood Estimation (MLE)**  \r\n",
    "3. **Singular Value Decomposition (SVD)**\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08214ae-5aea-40ac-8e67-dde6c1e2236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users (Tnu): 50\n",
      "Total number of items (Tni): 138\n",
      "\n",
      "Number of ratings for each item:\n",
      " write         49\n",
      "adulthood     49\n",
      "journey       49\n",
      "simile        49\n",
      "growing-up    49\n",
      "              ..\n",
      "yourself      41\n",
      "music         40\n",
      "women         40\n",
      "literature    40\n",
      "abilities     40\n",
      "Length: 138, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Sparsity: 10.22%\n",
      "Average rating across entire matrix: 2.975\n",
      "\n",
      "Target items chosen (lowest rated): I1=aliteracy, I2=understanding\n",
      "\n",
      "[Part 1] Step 3.2.1: I1=aliteracy Mean=2.4667, I2=understanding Mean=2.4889\n",
      "\n",
      "[Part 1] Covariance matrix shape: (138, 138)\n",
      "\n",
      "[Part 1] Top-5 peers for aliteracy: ['faith', 'attributed', 'philosophy', 'difficult', 'travel']\n",
      "[Part 1] Top-10 peers for aliteracy: ['faith', 'attributed', 'philosophy', 'difficult', 'travel', 'inspirational', 'learning', 'attributed-no-source', 'girls', 'dreams']\n",
      "[Part 1] Top-5 peers for understanding: ['activism', 'misattributed-to-mother-teresa', 'edison', 'opposite', 'fate']\n",
      "[Part 1] Top-10 peers for understanding: ['activism', 'misattributed-to-mother-teresa', 'edison', 'opposite', 'fate', 'lies', 'misattributed-mark-twain', 'miracles', 'books', 'fairy-tales']\n",
      "\n",
      "[Part 1] Predicted missing ratings for aliteracy with top-5 peers:\n",
      "User 13 -> 2.200\n",
      "User 16 -> 2.250\n",
      "User 19 -> 3.200\n",
      "User 24 -> 4.400\n",
      "User 44 -> 3.400\n",
      "\n",
      "[Part 1] Predicted missing ratings for understanding with top-5 peers:\n",
      "User 10 -> 2.200\n",
      "User 12 -> 3.750\n",
      "User 15 -> 2.400\n",
      "User 17 -> 4.000\n",
      "User 48 -> 3.200\n",
      "\n",
      "[Part 1] Predicted missing ratings for aliteracy with top-10 peers:\n",
      "User 13 -> 2.400\n",
      "User 16 -> 2.889\n",
      "User 19 -> 2.750\n",
      "User 24 -> 3.667\n",
      "User 44 -> 3.600\n",
      "\n",
      "[Part 1] Predicted missing ratings for understanding with top-10 peers:\n",
      "User 10 -> 2.444\n",
      "User 12 -> 3.333\n",
      "User 15 -> 3.000\n",
      "User 17 -> 3.000\n",
      "User 48 -> 3.222\n",
      "\n",
      "[Part 1] 3.2.12: Compare top-5 vs. top-10 predictions (I1 and I2).\n",
      "\n",
      "--- Comparison of top-5 vs. top-10 for I1 ---\n",
      "User 13: top-5 = 2.200, top-10 = 2.400, diff = 0.200\n",
      "User 16: top-5 = 2.250, top-10 = 2.889, diff = 0.639\n",
      "User 19: top-5 = 3.200, top-10 = 2.750, diff = -0.450\n",
      "User 24: top-5 = 4.400, top-10 = 3.667, diff = -0.733\n",
      "User 44: top-5 = 3.400, top-10 = 3.600, diff = 0.200\n",
      "\n",
      "--- Comparison of top-5 vs. top-10 for I2 ---\n",
      "User 10: top-5 = 2.200, top-10 = 2.444, diff = 0.244\n",
      "User 12: top-5 = 3.750, top-10 = 3.333, diff = -0.417\n",
      "User 15: top-5 = 2.400, top-10 = 3.000, diff = 0.600\n",
      "User 17: top-5 = 4.000, top-10 = 3.000, diff = -1.000\n",
      "User 48: top-5 = 3.200, top-10 = 3.222, diff = 0.022\n",
      "\n",
      "[Discussion/Comment for 3.2.12]\n",
      "- The numeric differences above show how using more peers (top-10) \n",
      "  can change the predicted ratings compared to only top-5 peers.\n",
      "- In your report, discuss which approach might be more accurate or practical,\n",
      "  and any factors influencing these differences (e.g., correlation, variance).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PART 1: PCA with Mean-Filling\n",
    "#  (Sections 3.1, 3.2 in the assignment)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# 1. Load the dataset (\"modified_dataset.csv\") from Assignment #1 (or #2)\n",
    "df = pd.read_csv(\"modified_dataset.csv\")\n",
    "\n",
    "# The dataset has 3 text columns: Quote, Author, Tags\n",
    "# Everything else from column index 3 onward are rating columns.\n",
    "rating_cols = df.columns[3:]\n",
    "rating_matrix = df[rating_cols].copy()  # NxM matrix (N=users, M=items)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.1.1, 3.1.2: The dataset is already on a 1-to-5 scale.\n",
    "# Count total number of users (Tnu), total number of items (Tni)\n",
    "# -----------------------------------------------------------------\n",
    "Tnu = rating_matrix.shape[0]\n",
    "Tni = rating_matrix.shape[1]\n",
    "\n",
    "print(\"Total number of users (Tnu):\", Tnu)\n",
    "print(\"Total number of items (Tni):\", Tni)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.1.5: Count number of ratings for every item\n",
    "# -----------------------------------------------------------------\n",
    "rating_counts = rating_matrix.notnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nNumber of ratings for each item:\\n\", rating_counts)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.1.6: Draw the distribution of ratings & assess sparsity\n",
    "# -----------------------------------------------------------------\n",
    "all_ratings_series = rating_matrix.values.flatten()\n",
    "all_ratings_series = all_ratings_series[~pd.isnull(all_ratings_series)]  # drop NaN\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(all_ratings_series, bins=[1,2,3,4,5,6], edgecolor='black', align='left')\n",
    "plt.title(\"Distribution of All Non-Null Ratings\")\n",
    "plt.xlabel(\"Rating Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.show()\n",
    "\n",
    "# Assess matrix sparsity\n",
    "total_possible = Tnu * Tni\n",
    "non_null_count = rating_matrix.notnull().sum().sum()\n",
    "sparsity = 1 - (non_null_count / total_possible)\n",
    "print(f\"Matrix Sparsity: {sparsity*100:.2f}%\")\n",
    "\n",
    "# Quick check for potential rating bias\n",
    "avg_rating = np.nanmean(rating_matrix.values)\n",
    "print(f\"Average rating across entire matrix: {avg_rating:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.1.7: Choose the two lowest rated items (I1, I2)\n",
    "#         using average rating across each item\n",
    "# -----------------------------------------------------------------\n",
    "item_means = rating_matrix.mean(axis=0)\n",
    "lowest_rated_items = item_means.sort_values().index[:2]\n",
    "I1, I2 = lowest_rated_items[0], lowest_rated_items[1]\n",
    "print(f\"\\nTarget items chosen (lowest rated): I1={I1}, I2={I2}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.1: Calculate average rating for I1 and I2\n",
    "# -----------------------------------------------------------------\n",
    "I1_mean = rating_matrix[I1].mean(skipna=True)\n",
    "I2_mean = rating_matrix[I2].mean(skipna=True)\n",
    "print(f\"\\n[Part 1] Step 3.2.1: I1={I1} Mean={I1_mean:.4f}, I2={I2} Mean={I2_mean:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.2: Replace missing ratings of I1 and I2 with their corresponding mean\n",
    "# -----------------------------------------------------------------\n",
    "pca_meanfill_data = rating_matrix.copy()\n",
    "pca_meanfill_data[I1] = pca_meanfill_data[I1].fillna(I1_mean)\n",
    "pca_meanfill_data[I2] = pca_meanfill_data[I2].fillna(I2_mean)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.3: Calculate the average rating for each item (entire matrix)\n",
    "# -----------------------------------------------------------------\n",
    "item_mean_all = pca_meanfill_data.mean(axis=0)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.4: For each item, calculate the difference between ratings and the mean\n",
    "# -----------------------------------------------------------------\n",
    "diff_matrix = pca_meanfill_data - item_mean_all\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.5 & 3.2.6: Compute pairwise covariance and generate covariance matrix\n",
    "# -----------------------------------------------------------------\n",
    "cov_matrix = diff_matrix.cov()  # item–item covariance\n",
    "print(\"\\n[Part 1] Covariance matrix shape:\", cov_matrix.shape)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.7: Determine the top-5 peers and top-10 peers for I1 and I2\n",
    "# -----------------------------------------------------------------\n",
    "def get_top_peers(cov_mat, item, top_k=5):\n",
    "    sorted_items = cov_mat[item].abs().sort_values(ascending=False)\n",
    "    top_peers = sorted_items.iloc[1:top_k+1].index.tolist()  # skip itself\n",
    "    return top_peers\n",
    "\n",
    "I1_top5 = get_top_peers(cov_matrix, I1, 5)\n",
    "I1_top10 = get_top_peers(cov_matrix, I1, 10)\n",
    "I2_top5  = get_top_peers(cov_matrix, I2, 5)\n",
    "I2_top10 = get_top_peers(cov_matrix, I2, 10)\n",
    "\n",
    "print(f\"\\n[Part 1] Top-5 peers for {I1}: {I1_top5}\")\n",
    "print(f\"[Part 1] Top-10 peers for {I1}: {I1_top10}\")\n",
    "print(f\"[Part 1] Top-5 peers for {I2}: {I2_top5}\")\n",
    "print(f\"[Part 1] Top-10 peers for {I2}: {I2_top10}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.8: Determine reduced dimensional space for each user\n",
    "#        in case of using the top-5 peers for each target item\n",
    "# -----------------------------------------------------------------\n",
    "def reduce_dimensional_space(data, target_item, top_peers_list):\n",
    "    selected_cols = [target_item] + top_peers_list\n",
    "    reduced_data = data[selected_cols].copy()\n",
    "    return reduced_data\n",
    "\n",
    "I1_reduced5 = reduce_dimensional_space(pca_meanfill_data, I1, I1_top5)\n",
    "I2_reduced5 = reduce_dimensional_space(pca_meanfill_data, I2, I2_top5)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.9: Predict missing ratings of I1, I2 (original missing)\n",
    "#        using top-5 peers (simple average approach)\n",
    "# -----------------------------------------------------------------\n",
    "def predict_with_peers(reduced_data, full_data, target_item, original_missing_mask):\n",
    "    predictions = {}\n",
    "    peers_cols = [c for c in reduced_data.columns if c != target_item]\n",
    "    for user_idx in full_data.index:\n",
    "        if original_missing_mask[user_idx]:  # user had missing rating originally\n",
    "            row_peers = reduced_data.loc[user_idx, peers_cols]\n",
    "            if row_peers.notna().sum() == 0:\n",
    "                predictions[user_idx] = np.nan\n",
    "            else:\n",
    "                predictions[user_idx] = row_peers.mean(skipna=True)\n",
    "    return predictions\n",
    "\n",
    "# Identify which users originally had missing for I1 or I2\n",
    "original_missing_I1 = rating_matrix[I1].isnull()\n",
    "original_missing_I2 = rating_matrix[I2].isnull()\n",
    "\n",
    "# Predict with top-5\n",
    "pred_I1_top5 = predict_with_peers(I1_reduced5, rating_matrix, I1, original_missing_I1)\n",
    "pred_I2_top5 = predict_with_peers(I2_reduced5, rating_matrix, I2, original_missing_I2)\n",
    "\n",
    "print(f\"\\n[Part 1] Predicted missing ratings for {I1} with top-5 peers:\")\n",
    "for k, v in pred_I1_top5.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "print(f\"\\n[Part 1] Predicted missing ratings for {I2} with top-5 peers:\")\n",
    "for k, v in pred_I2_top5.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.10 & 3.2.11: Repeat for top-10 peers\n",
    "# -----------------------------------------------------------------\n",
    "I1_reduced10 = reduce_dimensional_space(pca_meanfill_data, I1, I1_top10)\n",
    "I2_reduced10 = reduce_dimensional_space(pca_meanfill_data, I2, I2_top10)\n",
    "\n",
    "pred_I1_top10 = predict_with_peers(I1_reduced10, rating_matrix, I1, original_missing_I1)\n",
    "pred_I2_top10 = predict_with_peers(I2_reduced10, rating_matrix, I2, original_missing_I2)\n",
    "\n",
    "print(f\"\\n[Part 1] Predicted missing ratings for {I1} with top-10 peers:\")\n",
    "for k, v in pred_I1_top10.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "print(f\"\\n[Part 1] Predicted missing ratings for {I2} with top-10 peers:\")\n",
    "for k, v in pred_I2_top10.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.2.12: Compare the results of point 3.2.9 (top-5) with\n",
    "#         results of point 3.2.11 (top-10) for I1 and I2\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\n[Part 1] 3.2.12: Compare top-5 vs. top-10 predictions (I1 and I2).\")\n",
    "\n",
    "# Compare I1 predictions\n",
    "print(\"\\n--- Comparison of top-5 vs. top-10 for I1 ---\")\n",
    "for user in sorted(pred_I1_top5.keys()):  # users who had missing for I1\n",
    "    val5 = pred_I1_top5[user]\n",
    "    val10 = pred_I1_top10[user]\n",
    "    if val5 is not None and not np.isnan(val5) and val10 is not None and not np.isnan(val10):\n",
    "        diff = val10 - val5\n",
    "        print(f\"User {user}: top-5 = {val5:.3f}, top-10 = {val10:.3f}, diff = {diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: top-5 = {val5}, top-10 = {val10}, diff = N/A\")\n",
    "\n",
    "# Compare I2 predictions\n",
    "print(\"\\n--- Comparison of top-5 vs. top-10 for I2 ---\")\n",
    "for user in sorted(pred_I2_top5.keys()):  # users who had missing for I2\n",
    "    val5 = pred_I2_top5[user]\n",
    "    val10 = pred_I2_top10[user]\n",
    "    if val5 is not None and not np.isnan(val5) and val10 is not None and not np.isnan(val10):\n",
    "        diff = val10 - val5\n",
    "        print(f\"User {user}: top-5 = {val5:.3f}, top-10 = {val10:.3f}, diff = {diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: top-5 = {val5}, top-10 = {val10}, diff = N/A\")\n",
    "\n",
    "print(\"\"\"\n",
    "[Discussion/Comment for 3.2.12]\n",
    "- The numeric differences above show how using more peers (top-10) \n",
    "  can change the predicted ratings compared to only top-5 peers. \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94a51e9-ea1d-42d0-85d1-3a0a658b496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Part 2] MLE Cov: Top-5 peers for aliteracy: ['faith', 'attributed', 'philosophy', 'difficult', 'inspirational']\n",
      "[Part 2] MLE Cov: Top-10 peers for aliteracy: ['faith', 'attributed', 'philosophy', 'difficult', 'inspirational', 'travel', 'attributed-no-source', 'learning', 'girls', 'dreams']\n",
      "[Part 2] MLE Cov: Top-5 peers for understanding: ['activism', 'misattributed-to-mother-teresa', 'edison', 'opposite', 'fate']\n",
      "[Part 2] MLE Cov: Top-10 peers for understanding: ['activism', 'misattributed-to-mother-teresa', 'edison', 'opposite', 'fate', 'misattributed-mark-twain', 'lies', 'miracles', 'books', 'fairy-tales']\n",
      "\n",
      "[Part 2] MLE Cov: Predicted missing for aliteracy with top-5 peers:\n",
      "User 13 -> 2.600\n",
      "User 16 -> 2.250\n",
      "User 19 -> 2.800\n",
      "User 24 -> 4.000\n",
      "User 44 -> 3.600\n",
      "\n",
      "[Part 2] MLE Cov: Predicted missing for understanding with top-5 peers:\n",
      "User 10 -> 2.200\n",
      "User 12 -> 3.750\n",
      "User 15 -> 2.400\n",
      "User 17 -> 4.000\n",
      "User 48 -> 3.200\n",
      "\n",
      "[Part 2] MLE Cov: Predicted missing for aliteracy with top-10 peers:\n",
      "User 13 -> 2.400\n",
      "User 16 -> 2.889\n",
      "User 19 -> 2.750\n",
      "User 24 -> 3.667\n",
      "User 44 -> 3.600\n",
      "\n",
      "[Part 2] MLE Cov: Predicted missing for understanding with top-10 peers:\n",
      "User 10 -> 2.444\n",
      "User 12 -> 3.333\n",
      "User 15 -> 3.000\n",
      "User 17 -> 3.000\n",
      "User 48 -> 3.222\n",
      "\n",
      "[Part 2] 3.3.7: Code-based comparison of top-5 vs. top-10 predictions (MLE).\n",
      "\n",
      "--- MLE: Comparison of top-5 vs. top-10 for I1 ---\n",
      "User 13: top-5 = 2.600, top-10 = 2.400, diff = -0.200\n",
      "User 16: top-5 = 2.250, top-10 = 2.889, diff = 0.639\n",
      "User 19: top-5 = 2.800, top-10 = 2.750, diff = -0.050\n",
      "User 24: top-5 = 4.000, top-10 = 3.667, diff = -0.333\n",
      "User 44: top-5 = 3.600, top-10 = 3.600, diff = 0.000\n",
      "\n",
      "--- MLE: Comparison of top-5 vs. top-10 for I2 ---\n",
      "User 10: top-5 = 2.200, top-10 = 2.444, diff = 0.244\n",
      "User 12: top-5 = 3.750, top-10 = 3.333, diff = -0.417\n",
      "User 15: top-5 = 2.400, top-10 = 3.000, diff = 0.600\n",
      "User 17: top-5 = 4.000, top-10 = 3.000, diff = -1.000\n",
      "User 48: top-5 = 3.200, top-10 = 3.222, diff = 0.022\n",
      "\n",
      "[Comment for 3.3.7]\n",
      "- The above lines show numeric differences when using top-5 vs. top-10 peers \n",
      "  under the MLE-based covariance approach.\n",
      "\n",
      "\n",
      "[Part 2] 3.3.8: Compare Part 1 (Mean-Filling) top-5 vs. Part 2 (MLE) top-5 for I1, I2.\n",
      "\n",
      "--- I1: Part 1 top-5 vs. Part 2 (MLE) top-5 ---\n",
      "User 13: Part1=2.200, Part2(MLE)=2.600, diff=0.400\n",
      "User 16: Part1=2.250, Part2(MLE)=2.250, diff=0.000\n",
      "User 19: Part1=3.200, Part2(MLE)=2.800, diff=-0.400\n",
      "User 24: Part1=4.400, Part2(MLE)=4.000, diff=-0.400\n",
      "User 44: Part1=3.400, Part2(MLE)=3.600, diff=0.200\n",
      "\n",
      "--- I2: Part 1 top-5 vs. Part 2 (MLE) top-5 ---\n",
      "User 10: Part1=2.200, Part2(MLE)=2.200, diff=0.000\n",
      "User 12: Part1=3.750, Part2(MLE)=3.750, diff=0.000\n",
      "User 15: Part1=2.400, Part2(MLE)=2.400, diff=0.000\n",
      "User 17: Part1=4.000, Part2(MLE)=4.000, diff=0.000\n",
      "User 48: Part1=3.200, Part2(MLE)=3.200, diff=0.000\n",
      "\n",
      "[Comment for 3.3.8]\n",
      "- Here you see the difference between the Part 1 mean-filled covariance approach \n",
      "  and the Part 2 MLE-based approach, for top-5 predictions.\n",
      "\n",
      "\n",
      "[Part 2] 3.3.9: Compare Part 1 (Mean-Filling) top-10 vs. Part 2 (MLE) top-10 for I1, I2.\n",
      "\n",
      "--- I1: Part 1 top-10 vs. Part 2 (MLE) top-10 ---\n",
      "User 13: Part1=2.400, Part2(MLE)=2.400, diff=0.000\n",
      "User 16: Part1=2.889, Part2(MLE)=2.889, diff=0.000\n",
      "User 19: Part1=2.750, Part2(MLE)=2.750, diff=0.000\n",
      "User 24: Part1=3.667, Part2(MLE)=3.667, diff=0.000\n",
      "User 44: Part1=3.600, Part2(MLE)=3.600, diff=0.000\n",
      "\n",
      "--- I2: Part 1 top-10 vs. Part 2 (MLE) top-10 ---\n",
      "User 10: Part1=2.444, Part2(MLE)=2.444, diff=0.000\n",
      "User 12: Part1=3.333, Part2(MLE)=3.333, diff=0.000\n",
      "User 15: Part1=3.000, Part2(MLE)=3.000, diff=0.000\n",
      "User 17: Part1=3.000, Part2(MLE)=3.000, diff=0.000\n",
      "User 48: Part1=3.222, Part2(MLE)=3.222, diff=0.000\n",
      "\n",
      "[Comment for 3.3.9]\n",
      "- This compares the Part 1 mean-filled covariance approach \n",
      "  with the Part 2 MLE-based covariance, for top-10 predictions.\n",
      "- Observe whether MLE yields higher/lower estimates, or if some users get no prediction (NaN).\n",
      "\n",
      "\n",
      "[Additional Discussion for Part 2]\n",
      "- 3.3.7, 3.3.8, and 3.3.9 all highlight differences between:\n",
      "    (a) top-5 vs. top-10 under MLE, \n",
      "    (b) mean-fill PCA (Part 1) vs. MLE PCA (Part 2), \n",
      "  for both target items I1, I2.\n",
      "- Please elaborate on accuracy and the reasons behind these differences in your written report.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PART 2: PCA with MLE\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# (Reusing the same rating_matrix, I1, I2 from Part 1.)\n",
    "\n",
    "def mle_covariance(ratings_df):\n",
    "    \"\"\"\n",
    "    For each pair of items (i, j), consider only the users that have \n",
    "    specified ratings for both i and j. If there are no users in \n",
    "    common, the covariance = 0. Otherwise, compute np.cov(...) \n",
    "    for those overlapping ratings.\n",
    "    \"\"\"\n",
    "    items = ratings_df.columns\n",
    "    n_items = len(items)\n",
    "    cov_mat = pd.DataFrame(np.zeros((n_items, n_items)), index=items, columns=items)\n",
    "    \n",
    "    for i, col_i in enumerate(items):\n",
    "        for j, col_j in enumerate(items):\n",
    "            if i == j:\n",
    "                # Variance of item col_i\n",
    "                both_rated = ratings_df[col_i].notnull()\n",
    "                if both_rated.sum() > 1:\n",
    "                    cov_mat.loc[col_i, col_j] = ratings_df.loc[both_rated, col_i].var(ddof=1)\n",
    "                else:\n",
    "                    cov_mat.loc[col_i, col_j] = 0.0\n",
    "            elif i < j:\n",
    "                # Covariance between col_i and col_j\n",
    "                mask = ratings_df[col_i].notnull() & ratings_df[col_j].notnull()\n",
    "                if mask.sum() > 1:\n",
    "                    cov_val = np.cov(ratings_df.loc[mask, col_i],\n",
    "                                     ratings_df.loc[mask, col_j],\n",
    "                                     ddof=1)[0,1]\n",
    "                    cov_mat.loc[col_i, col_j] = cov_val\n",
    "                    cov_mat.loc[col_j, col_i] = cov_val\n",
    "                else:\n",
    "                    cov_mat.loc[col_i, col_j] = 0.0\n",
    "                    cov_mat.loc[col_j, col_i] = 0.0\n",
    "    return cov_mat\n",
    "\n",
    "# 3.3.1: Generate MLE-based covariance matrix\n",
    "pca_mle_data = rating_matrix.copy()  # No mean-filling here\n",
    "mle_cov_mat = mle_covariance(pca_mle_data)\n",
    "\n",
    "# 3.3.2: Determine top-5 and top-10 peers using MLE covariance\n",
    "I1_top5_mle = get_top_peers(mle_cov_mat, I1, 5)\n",
    "I1_top10_mle = get_top_peers(mle_cov_mat, I1, 10)\n",
    "I2_top5_mle  = get_top_peers(mle_cov_mat, I2, 5)\n",
    "I2_top10_mle = get_top_peers(mle_cov_mat, I2, 10)\n",
    "\n",
    "print(f\"\\n[Part 2] MLE Cov: Top-5 peers for {I1}:\", I1_top5_mle)\n",
    "print(f\"[Part 2] MLE Cov: Top-10 peers for {I1}:\", I1_top10_mle)\n",
    "print(f\"[Part 2] MLE Cov: Top-5 peers for {I2}:\", I2_top5_mle)\n",
    "print(f\"[Part 2] MLE Cov: Top-10 peers for {I2}:\", I2_top10_mle)\n",
    "\n",
    "# 3.3.3: Reduced space for top-5 peers\n",
    "I1_reduced5_mle = reduce_dimensional_space(pca_mle_data, I1, I1_top5_mle)\n",
    "I2_reduced5_mle = reduce_dimensional_space(pca_mle_data, I2, I2_top5_mle)\n",
    "\n",
    "# 3.3.4: Predict missing ratings (original) for I1, I2 with top-5 peers\n",
    "pred_I1_top5_mle = predict_with_peers(I1_reduced5_mle, rating_matrix, I1, original_missing_I1)\n",
    "pred_I2_top5_mle = predict_with_peers(I2_reduced5_mle, rating_matrix, I2, original_missing_I2)\n",
    "\n",
    "print(f\"\\n[Part 2] MLE Cov: Predicted missing for {I1} with top-5 peers:\")\n",
    "for k, v in pred_I1_top5_mle.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "print(f\"\\n[Part 2] MLE Cov: Predicted missing for {I2} with top-5 peers:\")\n",
    "for k, v in pred_I2_top5_mle.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "# 3.3.5: Reduced space for top-10 peers\n",
    "I1_reduced10_mle = reduce_dimensional_space(pca_mle_data, I1, I1_top10_mle)\n",
    "I2_reduced10_mle = reduce_dimensional_space(pca_mle_data, I2, I2_top10_mle)\n",
    "\n",
    "# 3.3.6: Predict missing ratings for I1, I2 with top-10 peers\n",
    "pred_I1_top10_mle = predict_with_peers(I1_reduced10_mle, rating_matrix, I1, original_missing_I1)\n",
    "pred_I2_top10_mle = predict_with_peers(I2_reduced10_mle, rating_matrix, I2, original_missing_I2)\n",
    "\n",
    "print(f\"\\n[Part 2] MLE Cov: Predicted missing for {I1} with top-10 peers:\")\n",
    "for k, v in pred_I1_top10_mle.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "print(f\"\\n[Part 2] MLE Cov: Predicted missing for {I2} with top-10 peers:\")\n",
    "for k, v in pred_I2_top10_mle.items():\n",
    "    print(f\"User {k} -> {v:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.3.7: Compare top-5 vs. top-10 in MLE approach (code-based)\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\n[Part 2] 3.3.7: Code-based comparison of top-5 vs. top-10 predictions (MLE).\")\n",
    "\n",
    "# Compare I1 (MLE)\n",
    "print(\"\\n--- MLE: Comparison of top-5 vs. top-10 for I1 ---\")\n",
    "for user in sorted(pred_I1_top5_mle.keys()):\n",
    "    val5 = pred_I1_top5_mle[user]\n",
    "    val10 = pred_I1_top10_mle.get(user, np.nan)\n",
    "    if not np.isnan(val5) and not np.isnan(val10):\n",
    "        diff = val10 - val5\n",
    "        print(f\"User {user}: top-5 = {val5:.3f}, top-10 = {val10:.3f}, diff = {diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: top-5 = {val5}, top-10 = {val10}, diff = N/A\")\n",
    "\n",
    "# Compare I2 (MLE)\n",
    "print(\"\\n--- MLE: Comparison of top-5 vs. top-10 for I2 ---\")\n",
    "for user in sorted(pred_I2_top5_mle.keys()):\n",
    "    val5 = pred_I2_top5_mle[user]\n",
    "    val10 = pred_I2_top10_mle.get(user, np.nan)\n",
    "    if not np.isnan(val5) and not np.isnan(val10):\n",
    "        diff = val10 - val5\n",
    "        print(f\"User {user}: top-5 = {val5:.3f}, top-10 = {val10:.3f}, diff = {diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: top-5 = {val5}, top-10 = {val10}, diff = N/A\")\n",
    "\n",
    "print(\"\"\"\n",
    "[Comment for 3.3.7]\n",
    "- The above lines show numeric differences when using top-5 vs. top-10 peers \n",
    "  under the MLE-based covariance approach.\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.3.8 & 3.3.9: Compare results with Part 1\n",
    "#  - 3.3.8: Compare results of 3.2.9 (Part 1 top-5) with 3.3.4 (Part 2 top-5).\n",
    "#  - 3.3.9: Compare results of 3.2.11 (Part 1 top-10) with 3.3.6 (Part 2 top-10).\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Part 2] 3.3.8: Compare Part 1 (Mean-Filling) top-5 vs. Part 2 (MLE) top-5 for I1, I2.\")\n",
    "\n",
    "# Compare I1 top-5 (part1) vs. I1 top-5 (MLE)\n",
    "print(\"\\n--- I1: Part 1 top-5 vs. Part 2 (MLE) top-5 ---\")\n",
    "for user in sorted(pred_I1_top5.keys()):\n",
    "    part1_val = pred_I1_top5[user]\n",
    "    part2_val = pred_I1_top5_mle.get(user, np.nan)\n",
    "    if not np.isnan(part1_val) and not np.isnan(part2_val):\n",
    "        diff = part2_val - part1_val\n",
    "        print(f\"User {user}: Part1={part1_val:.3f}, Part2(MLE)={part2_val:.3f}, diff={diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: Part1={part1_val}, Part2(MLE)={part2_val}, diff=N/A\")\n",
    "\n",
    "# Compare I2 top-5\n",
    "print(\"\\n--- I2: Part 1 top-5 vs. Part 2 (MLE) top-5 ---\")\n",
    "for user in sorted(pred_I2_top5.keys()):\n",
    "    part1_val = pred_I2_top5[user]\n",
    "    part2_val = pred_I2_top5_mle.get(user, np.nan)\n",
    "    if not np.isnan(part1_val) and not np.isnan(part2_val):\n",
    "        diff = part2_val - part1_val\n",
    "        print(f\"User {user}: Part1={part1_val:.3f}, Part2(MLE)={part2_val:.3f}, diff={diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: Part1={part1_val}, Part2(MLE)={part2_val}, diff=N/A\")\n",
    "\n",
    "print(\"\"\"\n",
    "[Comment for 3.3.8]\n",
    "- Here you see the difference between the Part 1 mean-filled covariance approach \n",
    "  and the Part 2 MLE-based approach, for top-5 predictions.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n[Part 2] 3.3.9: Compare Part 1 (Mean-Filling) top-10 vs. Part 2 (MLE) top-10 for I1, I2.\")\n",
    "\n",
    "# Compare I1 top-10 (part1) vs. I1 top-10 (MLE)\n",
    "print(\"\\n--- I1: Part 1 top-10 vs. Part 2 (MLE) top-10 ---\")\n",
    "for user in sorted(pred_I1_top10.keys()):\n",
    "    part1_val = pred_I1_top10[user]\n",
    "    part2_val = pred_I1_top10_mle.get(user, np.nan)\n",
    "    if not np.isnan(part1_val) and not np.isnan(part2_val):\n",
    "        diff = part2_val - part1_val\n",
    "        print(f\"User {user}: Part1={part1_val:.3f}, Part2(MLE)={part2_val:.3f}, diff={diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: Part1={part1_val}, Part2(MLE)={part2_val}, diff=N/A\")\n",
    "\n",
    "# Compare I2 top-10\n",
    "print(\"\\n--- I2: Part 1 top-10 vs. Part 2 (MLE) top-10 ---\")\n",
    "for user in sorted(pred_I2_top10.keys()):\n",
    "    part1_val = pred_I2_top10[user]\n",
    "    part2_val = pred_I2_top10_mle.get(user, np.nan)\n",
    "    if not np.isnan(part1_val) and not np.isnan(part2_val):\n",
    "        diff = part2_val - part1_val\n",
    "        print(f\"User {user}: Part1={part1_val:.3f}, Part2(MLE)={part2_val:.3f}, diff={diff:.3f}\")\n",
    "    else:\n",
    "        print(f\"User {user}: Part1={part1_val}, Part2(MLE)={part2_val}, diff=N/A\")\n",
    "\n",
    "print(\"\"\"\n",
    "[Comment for 3.3.9]\n",
    "- This compares the Part 1 mean-filled covariance approach \n",
    "  with the Part 2 MLE-based covariance, for top-10 predictions.\n",
    "- Observe whether MLE yields higher/lower estimates, or if some users get no prediction (NaN).\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "[Additional Discussion for Part 2]\n",
    "- 3.3.7, 3.3.8, and 3.3.9 all highlight differences between:\n",
    "    (a) top-5 vs. top-10 under MLE, \n",
    "    (b) mean-fill PCA (Part 1) vs. MLE PCA (Part 2), \n",
    "  for both target items I1, I2.\n",
    "- Please elaborate on accuracy and the reasons behind these differences in your written report.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae8b75c-7a84-48fb-ab9a-97399932ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Part 3] SVD: Reconstructed missing ratings for aliteracy:\n",
      "User 13 -> 1.785\n",
      "User 16 -> 1.417\n",
      "User 19 -> 2.886\n",
      "User 24 -> 2.022\n",
      "User 44 -> 2.317\n",
      "\n",
      "[Part 3] SVD: Reconstructed missing ratings for understanding:\n",
      "User 10 -> 2.266\n",
      "User 12 -> 2.403\n",
      "User 15 -> 2.417\n",
      "User 17 -> 1.940\n",
      "User 48 -> 2.304\n",
      "\n",
      "[Discussion & Conclusion]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PART 3: Singular Value Decomposition (SVD)\n",
    "# -----------------------------------------------------------------\n",
    "#   (1) Mean-fill the entire matrix again (3.4.1 & 3.4.2).\n",
    "#   (2) Then do SVD decomposition R = U Σ Vᵀ.\n",
    "#   (3) Reconstruct missing entries from the truncated SVD approach.\n",
    "\n",
    "# 3.4.1 and 3.4.2. We'll do the mean-filling method for the entire matrix (for all items).\n",
    "svd_data = rating_matrix.copy()\n",
    "item_means_full = svd_data.mean(axis=0)\n",
    "svd_filled = svd_data.fillna(item_means_full)  # mean-filling\n",
    "\n",
    "# 3.4.3. The assignment asks to compute eigenvalues/eigenvectors of the rating matrix\n",
    "# But the matrix is NxM, possibly non-square. So we'll do SVD directly with numpy or we could do the full PCA approach.\n",
    "# For demonstration, let's do standard SVD with numpy: R = U Σ Vᵀ\n",
    "R_filled = svd_filled.values  # NxM\n",
    "U, s, Vt = np.linalg.svd(R_filled, full_matrices=False)  # U: NxK, s: K, Vt: KxM\n",
    "# K = min(N, M)\n",
    "\n",
    "# 3.4.4 to 3.4.7 are about ensuring orthogonality, orthonormality, etc. \n",
    "# However, np.linalg.svd already yields orthonormal U and V. \n",
    "# If you want to replicate the steps (Gram-Schmidt, etc.) manually, you can, \n",
    "# but typically SVD from numpy is already orthonormal.\n",
    "\n",
    "# 3.4.8. Construct Σ from s\n",
    "Sigma = np.diag(s)  # shape KxK\n",
    "\n",
    "# 3.4.9. Construct the items matrix V̂ \n",
    "# In standard SVD, V (not Vᵀ) has columns = right singular vectors\n",
    "V = Vt.T  # shape MxK\n",
    "\n",
    "# 3.4.10. Construct the user matrix Û \n",
    "# U is NxK\n",
    "# The assignment's notion: U^ are the user factors, V^ are the item factors\n",
    "\n",
    "# 3.4.11. Reconstruct the rating matrix using truncated SVD\n",
    "# Let's pick a truncation rank k (for demonstration, let's do k=10 or smaller)\n",
    "k = 10 if len(s) >= 10 else len(s)\n",
    "U_k = U[:, :k]\n",
    "Sigma_k = np.diag(s[:k])\n",
    "V_k = V[:, :k]\n",
    "\n",
    "# R_hat = U_k Σ_k V_kᵀ\n",
    "R_hat = np.dot(np.dot(U_k, Sigma_k), V_k.T)\n",
    "\n",
    "# 3.4.12. Use R_hat to fill missing values for I1, I2\n",
    "reconstructed_df = pd.DataFrame(R_hat, index=svd_filled.index, columns=svd_filled.columns)\n",
    "svd_predictions_I1 = {}\n",
    "svd_predictions_I2 = {}\n",
    "for idx in rating_matrix.index:\n",
    "    if pd.isnull(rating_matrix.loc[idx, I1]):\n",
    "        svd_predictions_I1[idx] = reconstructed_df.loc[idx, I1]\n",
    "    if pd.isnull(rating_matrix.loc[idx, I2]):\n",
    "        svd_predictions_I2[idx] = reconstructed_df.loc[idx, I2]\n",
    "\n",
    "print(f\"\\n[Part 3] SVD: Reconstructed missing ratings for {I1}:\")\n",
    "for u, val in svd_predictions_I1.items():\n",
    "    print(f\"User {u} -> {val:.3f}\")\n",
    "\n",
    "print(f\"\\n[Part 3] SVD: Reconstructed missing ratings for {I2}:\")\n",
    "for u, val in svd_predictions_I2.items():\n",
    "    print(f\"User {u} -> {val:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3.5. Discussion & Conclusion\n",
    "# (This is where you summarize, compare, and discuss the pros/cons)\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\n[Discussion & Conclusion]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf34e84-2eae-4a09-9b63-ce09baedc22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
